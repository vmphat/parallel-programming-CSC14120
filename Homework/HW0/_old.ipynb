{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Họ tên: Vũ Minh Phát\n",
        "\n",
        "MSSV: 21127739"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW0: Làm quen với CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy`\n",
        "\n",
        "Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n",
        "Trong đó, 37 chính là compute capability của GPU Tesla K80.\n",
        "\n",
        "Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCkmnirl2xWF",
        "outputId": "fd3acbeb-54e6-4815-91b9-f953b8d1015a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-pmi72yS6"
      },
      "source": [
        "Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkZaH7EE-ocN"
      },
      "source": [
        "Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH9lSjFfr3Kw"
      },
      "source": [
        "## Câu 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvZB8iq3BIhw"
      },
      "source": [
        "**Đề bài**: Viết hàm và thử nghiệm in ra các thông tin của card màn hình như sau:\n",
        "- GPU card's name\n",
        "- GPU computation capabilities\n",
        "- Maximum number of block dimensions\n",
        "- Maximum number of grid dimensions\n",
        "- Maximum size of GPU memory\n",
        "- Amount of constant and share memory\n",
        "- Warp size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIGhLYgmB2tE"
      },
      "source": [
        "Sử dụng **nvcc** (CUDA Compiler) để biên dịch chương trình:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aZNqZuECjNso"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_{major}{minor} ./HW0_P1.cu -o gpu_info_21127739"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-UfAoa9CkJM"
      },
      "source": [
        "Sau khi biên dịch thành công, ta chạy thử nghiệm chương trình:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVFUj14OYUyy",
        "outputId": "9df58700-cd17-4f2c-c45c-de545f40c5a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CUDA-capable devices: 1\n",
            "\n",
            "Device 0:\n",
            "===== GPU Information =====\n",
            "GPU name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Maximum block dimensions: (1024, 1024, 64)\n",
            "Maximum grid dimensions: (2147483647, 65535, 65535)\n",
            "Total global memory: 14.75 GB\n",
            "Total constant memory: 64.00 KB\n",
            "Total shared memory per block: 48.00 KB\n",
            "Total shared memory per multiprocessor: 64.00 KB\n",
            "Warp size: 32\n",
            "===========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!./gpu_info_21127739"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb37nC_TFE_y"
      },
      "source": [
        "> **Tài liệu tham khảo**:  \n",
        "> [1] Thông tin của cấu trúc `cudaDeviceProp` - [docs.nvidia.com](https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html).  \n",
        "> [2] Gist \"Get Information about CUDA cards on your system\" by Steven Borrelli - [gist.github.com/stevendborrelli](https://gist.github.com/stevendborrelli/4286842).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlycLWxberDO"
      },
      "source": [
        "## Câu 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8CXC1VTaDJA"
      },
      "source": [
        "**Đề bài**:\n",
        "- Hãy viết chương trình cộng hai vector. Tuy nhiên, mỗi thread sẽ thực hiện hai phép tính cộng trên hai phần tử của mảng thay vì một phần tử như trong bài giảng lý thuyết (và file demo `01-AddVector.cu`).\n",
        "\n",
        "- Cài đặt cả hai version được yêu cầu trong bài tập, thực hiện thử nghiệm với kích thước block `256`, biên dịch file code và chạy với các kích thước mảng `N` khác nhau. Ghi nhận thời gian chạy vào bảng kết quả tổng hợp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUNE_7kpaDJA"
      },
      "source": [
        "Sử dụng **nvcc** (CUDA Compiler) để biên dịch chương trình:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gE-rY5TesEFe"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_{major}{minor} ./HW0_P2.cu -o vector_addition_21127739"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHWhW2BUaDJA"
      },
      "source": [
        "Sau khi biên dịch thành công, ta chạy thử nghiệm chương trình:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG1mOFWW7zlB",
        "outputId": "2dafce21-45f8-4aa5-efee-8c80b121ff17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== GPU Information =====\n",
            "GPU name: Tesla T4\n",
            "GPU compute capability: 7.5\n",
            "===========================\n",
            "\n",
            "________[ Running test cases ]________\n",
            "Vector size N = 1 ... passed\n",
            "Vector size N = 64 ... passed\n",
            "Vector size N = 256 ... passed\n",
            "Vector size N = 1024 ... passed\n",
            "Vector size N = 4096 ... passed\n",
            "Vector size N = 16384 ... passed\n",
            "Vector size N = 65536 ... passed\n",
            "Vector size N = 262144 ... passed\n",
            "Vector size N = 1048576 ... passed\n",
            "Vector size N = 4194304 ... passed\n",
            "Vector size N = 16777216 ... passed\n",
            "‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾\n",
            "\n",
            "[===== Result summary =====]\n",
            "*-------------*-------------------*-------------------*-------------------*\n",
            "| Vector size |  Host time (ms)   | Device time (ms)  | Device time (ms)  |\n",
            "|             |                   |    (Version 1)    |    (Version 2)    |\n",
            "*-------------+-------------------+-------------------+-------------------*\n",
            "| 64          | 0.009             | 0.022             | 0.029             |\n",
            "| 256         | 0.009             | 0.020             | 0.020             |\n",
            "| 1024        | 0.011             | 0.020             | 0.019             |\n",
            "| 4096        | 0.029             | 0.022             | 0.018             |\n",
            "| 16384       | 0.090             | 0.021             | 0.020             |\n",
            "| 65536       | 0.360             | 0.025             | 0.024             |\n",
            "| 262144      | 1.410             | 0.033             | 0.034             |\n",
            "| 1048576     | 5.695             | 0.075             | 0.085             |\n",
            "| 4194304     | 22.187            | 0.221             | 0.283             |\n",
            "| 16777216    | 88.442            | 0.800             | 1.019             |\n",
            "*-------------*-------------------*-------------------*-------------------*\n"
          ]
        }
      ],
      "source": [
        "!./vector_addition_21127739"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea63ryaCaDJB"
      },
      "source": [
        "Bảng kết quả tổng hợp sau khi chạy thử nghiệm chương trình cộng hai vector với các thông số thiết lập được mô tả trong yêu cầu:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrZFx9DAaDJB"
      },
      "source": [
        "| Vector size |  Host time (ms)   | Device time (ms)<br>(Version 1)  | Device time (ms)<br>(Version 2)  |\n",
        "| --- | --: | --: | --: |\n",
        "| 64          | 0.009             | 0.022             | 0.029             |\n",
        "| 256         | 0.009             | 0.020             | 0.020             |\n",
        "| 1024        | 0.011             | 0.020             | 0.019             |\n",
        "| 4096        | 0.029             | 0.022             | 0.018             |\n",
        "| 16384       | 0.090             | 0.021             | 0.020             |\n",
        "| 65536       | 0.360             | 0.025             | 0.024             |\n",
        "| 262144      | 1.410             | 0.033             | 0.034             |\n",
        "| 1048576     | 5.695             | 0.075             | 0.085             |\n",
        "| 4194304     | 22.187            | 0.221             | 0.283             |\n",
        "| 16777216    | 88.442            | 0.800             | 1.019             |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7JIvsDBaDJB"
      },
      "source": [
        "**Nhận xét**:\n",
        "- Nhìn chung, nếu chỉ xét đến thời gian chạy các phép tính cộng trên hai mảng (không kể đến thời gian: cấp phát, sao chép, hủy, v.v. trên vùng nhớ), thì ta thấy việc chạy chương trình trên GPU (device) có thể tiết kiệm rất nhiều thời gian so với khi chạy trên CPU (host). Điều này cho thấy hiệu suất vượt trội của GPU so với CPU trong các tác vụ có khả năng song song hóa cao như việc tính toán trên mảng (vector) hay ma trận.\n",
        "\n",
        "- Khi xét riêng hai phiên bản của chương trình cộng hai vector trên GPU, ta thấy chúng đều cho ra hiệu suất tương đồng với nhau, tuy có một chút sự khác biệt nhưng không đáng kể."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "701mQgkoaDJB"
      },
      "source": [
        "> **Tài liệu tham khảo**:  \n",
        "> [1] File demo `01-AddVector.cu` được cung cấp trong môn học.  \n",
        "> [2] Repository \"Vector Addition (CUDA)\" by Thomas Papatheodore - [github.com/olcf-tutorials](https://github.com/olcf-tutorials/vector_addition_cuda).  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "graphmining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
